{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model Implementation: SMS Spam Detection\n",
    "\n",
    "## 1. Introduction\n",
    "In this project, we will build a machine learning model to classify SMS messages as either **Spam** or **Ham** (legitimate). We will use the **SMS Spam Collection Dataset**, which is a set of SMS tagged messages that have been collected for SMS Spam research.\n",
    "\n",
    "### Objectives:\n",
    "- Load and explore the dataset.\n",
    "- Preprocess the text data (cleaning, vectorization).\n",
    "- Perform Exploratory Data Analysis (EDA).\n",
    "- Train multiple machine learning models (Logistic Regression, Random Forest, SVM, Naive Bayes, KNN).\n",
    "- Evaluate the models using accuracy, precision, recall, F1-score, and confusion matrices.\n",
    "- Compare the performance of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Overview\n",
    "We will load the `spam.csv` file. Note that this dataset often contains some encoding issues, so we'll try loading it with `latin-1` encoding if utf-8 fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset not found. Please ensure 'spam.csv' is in the same directory.\")\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "The dataset often contains unnecessary columns (Unnamed: 2, 3, 4) due to parsing errors or empty fields in the original csv. We will drop them and rename the main columns to something more meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True, errors='ignore')\n",
    "\n",
    "# Rename columns\n",
    "df.rename(columns={'v1': 'label', 'v2': 'message'}, inplace=True)\n",
    "\n",
    "# Check info and null values\n",
    "print(df.info())\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Check for duplicates\n",
    "print(\"\\nNumber of duplicates:\", df.duplicated().sum())\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(\"Number of duplicates after removal:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Spam vs Ham\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='label', data=df, palette='viridis')\n",
    "plt.title('Distribution of Spam vs Ham Messages')\n",
    "plt.show()\n",
    "\n",
    "# Calculate percentage\n",
    "print(df['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering: Message Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length'] = df['message'].apply(len)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(df[df['label'] == 'ham']['length'], bins=50, alpha=0.7, label='Ham')\n",
    "sns.histplot(df[df['label'] == 'spam']['length'], bins=50, alpha=0.7, color='red', label='Spam')\n",
    "plt.legend()\n",
    "plt.title('Message Length Distribution: Spam vs Ham')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: Spam messages tend to be longer than ham messages on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing\n",
    "- **Label Encoding**: Convert 'spam'/'ham' to 1/0.\n",
    "- **Text Vectorization**: Convert text messages into numerical vectors using TF-IDF (Term Frequency-Inverse Document Frequency).\n",
    "- **Train-Test Split**: Split data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "encoder = LabelEncoder()\n",
    "df['label_num'] = encoder.fit_transform(df['label'])\n",
    "\n",
    "# X and y\n",
    "X = df['message']\n",
    "y = df['label_num']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=3000, stop_words='english')\n",
    "X_train_tfidf = tfidf.fit_transform(X_train).toarray()\n",
    "X_test_tfidf = tfidf.transform(X_test).toarray()\n",
    "\n",
    "print(\"Training Shape:\", X_train_tfidf.shape)\n",
    "print(\"Testing Shape:\", X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training & Evaluation\n",
    "We will train and evaluate the following models:\n",
    "1. **Logistic Regression**\n",
    "2. **Random Forest Classifier**\n",
    "3. **Support Vector Machine (SVM)**\n",
    "4. **Multinomial Naive Bayes**\n",
    "5. **K-Nearest Neighbors (KNN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"KNN\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = [acc, prec, rec, f1]\n",
    "    \n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results, index=['Accuracy', 'Precision', 'Recall', 'F1-Score']).T\n",
    "results_df = results_df.sort_values(by='Accuracy', ascending=False)\n",
    "print(results_df)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=results_df.index, y=results_df['Accuracy'], palette='magma')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.ylim(0.8, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix of the Best Model\n",
    "Let's visualize the confusion matrix for **Multinomial Naive Bayes** (often the best for text data) or the highest accuracy model found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking Naive Bayes as a representative high-performer for text\n",
    "nb_model = models['Naive Bayes']\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_nb)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Naive Bayes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "- We successfully trained multiple models to detect spam SMS messages.\n",
    "- Text preprocessing involved Label Encoding and TF-IDF Vectorization.\n",
    "- **Naive Bayes** and **Support Vector Machines (SVM)** typically perform exceptionally well on text classification tasks.\n",
    "- The project demonstrates a full ML pipeline from data loading to model evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
